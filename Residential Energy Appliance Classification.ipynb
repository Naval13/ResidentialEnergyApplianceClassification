{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION:\n",
    "\n",
    "The objective is to develop classification models for different appliances used in the household. The load monitoring is done to provide detailed electricity consumption information and usage of individual appliances in residential buildings. Our aim is to develop a classifier to detect whether the target appliances are being used in each time interval. Python language is used to develop the classification models as it provides a wide variety of libraries for time series, feature extraction and machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below statements are for the dataframe for ac\n",
      "Number of rows before removing duplicates from Train Dataframe: 417720\n",
      "Number of rows after removing duplicates from Train Dataframe: 417720\n",
      "Number of rows before removing missing values from Train Dataframe: 417720\n",
      "Number of rows after removing missing values from Train Dataframe: 417720\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for ev\n",
      "Number of rows before removing duplicates from Train Dataframe: 417720\n",
      "Number of rows after removing duplicates from Train Dataframe: 417720\n",
      "Number of rows before removing missing values from Train Dataframe: 417720\n",
      "Number of rows after removing missing values from Train Dataframe: 417720\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for oven\n",
      "Number of rows before removing duplicates from Train Dataframe: 417720\n",
      "Number of rows after removing duplicates from Train Dataframe: 417720\n",
      "Number of rows before removing missing values from Train Dataframe: 417720\n",
      "Number of rows after removing missing values from Train Dataframe: 417720\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for wash\n",
      "Number of rows before removing duplicates from Train Dataframe: 417720\n",
      "Number of rows after removing duplicates from Train Dataframe: 417720\n",
      "Number of rows before removing missing values from Train Dataframe: 417720\n",
      "Number of rows after removing missing values from Train Dataframe: 417720\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for dryer\n",
      "Number of rows before removing duplicates from Train Dataframe: 417720\n",
      "Number of rows after removing duplicates from Train Dataframe: 417720\n",
      "Number of rows before removing missing values from Train Dataframe: 417720\n",
      "Number of rows after removing missing values from Train Dataframe: 417720\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for ac\n",
      "Number of rows before removing duplicates from Test Dataframe: 105540\n",
      "Number of rows before removing missing values from Test Dataframe: 105540\n",
      "Number of rows after removing missing values from Test Dataframe: 105540\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for ev\n",
      "Number of rows before removing duplicates from Test Dataframe: 105540\n",
      "Number of rows before removing missing values from Test Dataframe: 105540\n",
      "Number of rows after removing missing values from Test Dataframe: 105540\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for oven\n",
      "Number of rows before removing duplicates from Test Dataframe: 105540\n",
      "Number of rows before removing missing values from Test Dataframe: 105540\n",
      "Number of rows after removing missing values from Test Dataframe: 105540\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for wash\n",
      "Number of rows before removing duplicates from Test Dataframe: 105540\n",
      "Number of rows before removing missing values from Test Dataframe: 105540\n",
      "Number of rows after removing missing values from Test Dataframe: 105540\n",
      "\n",
      "\n",
      "The below statements are for the dataframe for dryer\n",
      "Number of rows before removing duplicates from Test Dataframe: 105540\n",
      "Number of rows before removing missing values from Test Dataframe: 105540\n",
      "Number of rows after removing missing values from Test Dataframe: 105540\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [00:25<00:00,  3.92it/s]\n",
      "Feature Extraction: 100%|██████████| 99/99 [00:05<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: ac\n",
      "\n",
      "0:\tlearn: 0.4153349\ttotal: 1.4s\tremaining: 1m 8s\n",
      "1:\tlearn: 0.2518350\ttotal: 3.55s\tremaining: 1m 25s\n",
      "2:\tlearn: 0.1585842\ttotal: 5.11s\tremaining: 1m 20s\n",
      "3:\tlearn: 0.1073081\ttotal: 6.45s\tremaining: 1m 14s\n",
      "4:\tlearn: 0.0795874\ttotal: 7.63s\tremaining: 1m 8s\n",
      "5:\tlearn: 0.0627084\ttotal: 8.85s\tremaining: 1m 4s\n",
      "6:\tlearn: 0.0491076\ttotal: 9.98s\tremaining: 1m 1s\n",
      "7:\tlearn: 0.0400897\ttotal: 11.1s\tremaining: 58.5s\n",
      "8:\tlearn: 0.0341203\ttotal: 12.4s\tremaining: 56.3s\n",
      "9:\tlearn: 0.0300008\ttotal: 13.6s\tremaining: 54.3s\n",
      "10:\tlearn: 0.0270095\ttotal: 14.7s\tremaining: 52.2s\n",
      "11:\tlearn: 0.0246721\ttotal: 16.1s\tremaining: 51s\n",
      "12:\tlearn: 0.0230699\ttotal: 17.4s\tremaining: 49.5s\n",
      "13:\tlearn: 0.0213968\ttotal: 18.5s\tremaining: 47.6s\n",
      "14:\tlearn: 0.0199259\ttotal: 19.9s\tremaining: 46.4s\n",
      "15:\tlearn: 0.0192003\ttotal: 21.3s\tremaining: 45.2s\n",
      "16:\tlearn: 0.0182339\ttotal: 22.3s\tremaining: 43.3s\n",
      "17:\tlearn: 0.0175672\ttotal: 23.4s\tremaining: 41.6s\n",
      "18:\tlearn: 0.0167914\ttotal: 24.8s\tremaining: 40.4s\n",
      "19:\tlearn: 0.0162423\ttotal: 26.1s\tremaining: 39.2s\n",
      "20:\tlearn: 0.0157449\ttotal: 27.5s\tremaining: 38s\n",
      "21:\tlearn: 0.0152069\ttotal: 28.7s\tremaining: 36.6s\n",
      "22:\tlearn: 0.0148417\ttotal: 30.1s\tremaining: 35.3s\n",
      "23:\tlearn: 0.0142888\ttotal: 31.2s\tremaining: 33.8s\n",
      "24:\tlearn: 0.0140642\ttotal: 32.3s\tremaining: 32.3s\n",
      "25:\tlearn: 0.0134667\ttotal: 33.4s\tremaining: 30.8s\n",
      "26:\tlearn: 0.0131191\ttotal: 34.4s\tremaining: 29.3s\n",
      "27:\tlearn: 0.0126982\ttotal: 35.4s\tremaining: 27.8s\n",
      "28:\tlearn: 0.0123148\ttotal: 36.5s\tremaining: 26.4s\n",
      "29:\tlearn: 0.0120050\ttotal: 37.5s\tremaining: 25s\n",
      "30:\tlearn: 0.0117685\ttotal: 38.5s\tremaining: 23.6s\n",
      "31:\tlearn: 0.0115388\ttotal: 39.7s\tremaining: 22.3s\n",
      "32:\tlearn: 0.0111601\ttotal: 40.8s\tremaining: 21s\n",
      "33:\tlearn: 0.0109282\ttotal: 42s\tremaining: 19.7s\n",
      "34:\tlearn: 0.0106305\ttotal: 43.2s\tremaining: 18.5s\n",
      "35:\tlearn: 0.0104587\ttotal: 44.2s\tremaining: 17.2s\n",
      "36:\tlearn: 0.0101739\ttotal: 45.3s\tremaining: 15.9s\n",
      "37:\tlearn: 0.0099953\ttotal: 47s\tremaining: 14.9s\n",
      "38:\tlearn: 0.0097265\ttotal: 48.4s\tremaining: 13.6s\n",
      "39:\tlearn: 0.0095501\ttotal: 49.4s\tremaining: 12.3s\n",
      "40:\tlearn: 0.0093889\ttotal: 50.4s\tremaining: 11.1s\n",
      "41:\tlearn: 0.0091536\ttotal: 51.7s\tremaining: 9.84s\n",
      "42:\tlearn: 0.0090532\ttotal: 52.9s\tremaining: 8.62s\n",
      "43:\tlearn: 0.0088988\ttotal: 54.8s\tremaining: 7.47s\n",
      "44:\tlearn: 0.0087579\ttotal: 56.2s\tremaining: 6.25s\n",
      "45:\tlearn: 0.0085127\ttotal: 57.7s\tremaining: 5.02s\n",
      "46:\tlearn: 0.0083627\ttotal: 59.1s\tremaining: 3.77s\n",
      "47:\tlearn: 0.0082088\ttotal: 1m\tremaining: 2.51s\n",
      "48:\tlearn: 0.0080538\ttotal: 1m 2s\tremaining: 1.26s\n",
      "49:\tlearn: 0.0079550\ttotal: 1m 3s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: ac\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [00:08<00:00, 12.37it/s]\n",
      "Feature Extraction: 100%|██████████| 96/96 [00:01<00:00, 53.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LogisticRegression model for label: ev\n",
      "\n",
      "Finished building LogisticRegression model for label: ev\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [01:21<00:00,  1.23it/s]\n",
      "Feature Extraction: 100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: oven\n",
      "\n",
      "0:\tlearn: 0.4883140\ttotal: 1.2s\tremaining: 58.8s\n",
      "1:\tlearn: 0.3545935\ttotal: 2.3s\tremaining: 55.2s\n",
      "2:\tlearn: 0.2692829\ttotal: 3.51s\tremaining: 55s\n",
      "3:\tlearn: 0.2126644\ttotal: 4.63s\tremaining: 53.3s\n",
      "4:\tlearn: 0.1768594\ttotal: 5.69s\tremaining: 51.2s\n",
      "5:\tlearn: 0.1486666\ttotal: 6.68s\tremaining: 49s\n",
      "6:\tlearn: 0.1282920\ttotal: 7.72s\tremaining: 47.4s\n",
      "7:\tlearn: 0.1117640\ttotal: 8.81s\tremaining: 46.3s\n",
      "8:\tlearn: 0.0984935\ttotal: 9.83s\tremaining: 44.8s\n",
      "9:\tlearn: 0.0894134\ttotal: 10.9s\tremaining: 43.7s\n",
      "10:\tlearn: 0.0811792\ttotal: 12s\tremaining: 42.7s\n",
      "11:\tlearn: 0.0745617\ttotal: 13.2s\tremaining: 41.7s\n",
      "12:\tlearn: 0.0703409\ttotal: 14.4s\tremaining: 40.9s\n",
      "13:\tlearn: 0.0642889\ttotal: 15.5s\tremaining: 39.9s\n",
      "14:\tlearn: 0.0605929\ttotal: 16.5s\tremaining: 38.5s\n",
      "15:\tlearn: 0.0570588\ttotal: 17.5s\tremaining: 37.1s\n",
      "16:\tlearn: 0.0536220\ttotal: 18.5s\tremaining: 35.9s\n",
      "17:\tlearn: 0.0514037\ttotal: 19.6s\tremaining: 34.9s\n",
      "18:\tlearn: 0.0485824\ttotal: 20.7s\tremaining: 33.7s\n",
      "19:\tlearn: 0.0465300\ttotal: 21.7s\tremaining: 32.5s\n",
      "20:\tlearn: 0.0448600\ttotal: 22.6s\tremaining: 31.2s\n",
      "21:\tlearn: 0.0430352\ttotal: 23.7s\tremaining: 30.1s\n",
      "22:\tlearn: 0.0408695\ttotal: 24.7s\tremaining: 28.9s\n",
      "23:\tlearn: 0.0387750\ttotal: 25.7s\tremaining: 27.8s\n",
      "24:\tlearn: 0.0371327\ttotal: 26.9s\tremaining: 26.9s\n",
      "25:\tlearn: 0.0357698\ttotal: 28s\tremaining: 25.8s\n",
      "26:\tlearn: 0.0344981\ttotal: 29s\tremaining: 24.7s\n",
      "27:\tlearn: 0.0332557\ttotal: 29.9s\tremaining: 23.5s\n",
      "28:\tlearn: 0.0320056\ttotal: 30.9s\tremaining: 22.4s\n",
      "29:\tlearn: 0.0309670\ttotal: 31.9s\tremaining: 21.3s\n",
      "30:\tlearn: 0.0297633\ttotal: 33s\tremaining: 20.2s\n",
      "31:\tlearn: 0.0288103\ttotal: 33.9s\tremaining: 19.1s\n",
      "32:\tlearn: 0.0281506\ttotal: 34.9s\tremaining: 18s\n",
      "33:\tlearn: 0.0275511\ttotal: 35.9s\tremaining: 16.9s\n",
      "34:\tlearn: 0.0267532\ttotal: 36.9s\tremaining: 15.8s\n",
      "35:\tlearn: 0.0261815\ttotal: 38.2s\tremaining: 14.8s\n",
      "36:\tlearn: 0.0255386\ttotal: 39.2s\tremaining: 13.8s\n",
      "37:\tlearn: 0.0250941\ttotal: 40.1s\tremaining: 12.7s\n",
      "38:\tlearn: 0.0244106\ttotal: 41.4s\tremaining: 11.7s\n",
      "39:\tlearn: 0.0237906\ttotal: 42.6s\tremaining: 10.6s\n",
      "40:\tlearn: 0.0232709\ttotal: 43.7s\tremaining: 9.59s\n",
      "41:\tlearn: 0.0224750\ttotal: 44.8s\tremaining: 8.53s\n",
      "42:\tlearn: 0.0218602\ttotal: 45.8s\tremaining: 7.46s\n",
      "43:\tlearn: 0.0213692\ttotal: 46.7s\tremaining: 6.37s\n",
      "44:\tlearn: 0.0210548\ttotal: 47.8s\tremaining: 5.31s\n",
      "45:\tlearn: 0.0206949\ttotal: 48.8s\tremaining: 4.25s\n",
      "46:\tlearn: 0.0199944\ttotal: 49.9s\tremaining: 3.19s\n",
      "47:\tlearn: 0.0194797\ttotal: 50.9s\tremaining: 2.12s\n",
      "48:\tlearn: 0.0188938\ttotal: 51.9s\tremaining: 1.06s\n",
      "49:\tlearn: 0.0183001\ttotal: 53s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: oven\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n",
      "Feature Extraction: 100%|██████████| 100/100 [00:20<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: wash\n",
      "\n",
      "0:\tlearn: 0.6001776\ttotal: 1.26s\tremaining: 1m 1s\n",
      "1:\tlearn: 0.5287165\ttotal: 2.52s\tremaining: 1m\n",
      "2:\tlearn: 0.4807273\ttotal: 4.02s\tremaining: 1m 2s\n",
      "3:\tlearn: 0.4472775\ttotal: 5.33s\tremaining: 1m 1s\n",
      "4:\tlearn: 0.4150371\ttotal: 6.8s\tremaining: 1m 1s\n",
      "5:\tlearn: 0.3865736\ttotal: 8.04s\tremaining: 59s\n",
      "6:\tlearn: 0.3734562\ttotal: 9.35s\tremaining: 57.5s\n",
      "7:\tlearn: 0.3609680\ttotal: 10.8s\tremaining: 56.7s\n",
      "8:\tlearn: 0.3418632\ttotal: 12s\tremaining: 54.4s\n",
      "9:\tlearn: 0.3282036\ttotal: 13.1s\tremaining: 52.3s\n",
      "10:\tlearn: 0.3203937\ttotal: 14.2s\tremaining: 50.3s\n",
      "11:\tlearn: 0.3058220\ttotal: 15.3s\tremaining: 48.6s\n",
      "12:\tlearn: 0.2973277\ttotal: 16.5s\tremaining: 47s\n",
      "13:\tlearn: 0.2873282\ttotal: 17.7s\tremaining: 45.4s\n",
      "14:\tlearn: 0.2730401\ttotal: 18.8s\tremaining: 44s\n",
      "15:\tlearn: 0.2643064\ttotal: 19.9s\tremaining: 42.3s\n",
      "16:\tlearn: 0.2517835\ttotal: 21s\tremaining: 40.8s\n",
      "17:\tlearn: 0.2445017\ttotal: 22.2s\tremaining: 39.4s\n",
      "18:\tlearn: 0.2376645\ttotal: 23.3s\tremaining: 38s\n",
      "19:\tlearn: 0.2318810\ttotal: 24.3s\tremaining: 36.5s\n",
      "20:\tlearn: 0.2246472\ttotal: 25.4s\tremaining: 35.1s\n",
      "21:\tlearn: 0.2181498\ttotal: 26.6s\tremaining: 33.8s\n",
      "22:\tlearn: 0.2127148\ttotal: 27.7s\tremaining: 32.6s\n",
      "23:\tlearn: 0.2069462\ttotal: 28.9s\tremaining: 31.3s\n",
      "24:\tlearn: 0.2005885\ttotal: 30s\tremaining: 30s\n",
      "25:\tlearn: 0.1946294\ttotal: 31.2s\tremaining: 28.8s\n",
      "26:\tlearn: 0.1886817\ttotal: 32.3s\tremaining: 27.5s\n",
      "27:\tlearn: 0.1857403\ttotal: 33.4s\tremaining: 26.2s\n",
      "28:\tlearn: 0.1818018\ttotal: 34.6s\tremaining: 25.1s\n",
      "29:\tlearn: 0.1782969\ttotal: 35.7s\tremaining: 23.8s\n",
      "30:\tlearn: 0.1748445\ttotal: 36.9s\tremaining: 22.6s\n",
      "31:\tlearn: 0.1733307\ttotal: 38s\tremaining: 21.4s\n",
      "32:\tlearn: 0.1691406\ttotal: 39.1s\tremaining: 20.1s\n",
      "33:\tlearn: 0.1644331\ttotal: 40.2s\tremaining: 18.9s\n",
      "34:\tlearn: 0.1607502\ttotal: 41.4s\tremaining: 17.8s\n",
      "35:\tlearn: 0.1578760\ttotal: 42.6s\tremaining: 16.6s\n",
      "36:\tlearn: 0.1530237\ttotal: 43.8s\tremaining: 15.4s\n",
      "37:\tlearn: 0.1493128\ttotal: 45s\tremaining: 14.2s\n",
      "38:\tlearn: 0.1449774\ttotal: 46.3s\tremaining: 13.1s\n",
      "39:\tlearn: 0.1412810\ttotal: 47.4s\tremaining: 11.9s\n",
      "40:\tlearn: 0.1392025\ttotal: 48.5s\tremaining: 10.6s\n",
      "41:\tlearn: 0.1365426\ttotal: 49.6s\tremaining: 9.44s\n",
      "42:\tlearn: 0.1330710\ttotal: 50.7s\tremaining: 8.25s\n",
      "43:\tlearn: 0.1300628\ttotal: 51.8s\tremaining: 7.07s\n",
      "44:\tlearn: 0.1265636\ttotal: 53s\tremaining: 5.88s\n",
      "45:\tlearn: 0.1243273\ttotal: 54s\tremaining: 4.69s\n",
      "46:\tlearn: 0.1209047\ttotal: 55.1s\tremaining: 3.52s\n",
      "47:\tlearn: 0.1191225\ttotal: 56.2s\tremaining: 2.34s\n",
      "48:\tlearn: 0.1174577\ttotal: 57.4s\tremaining: 1.17s\n",
      "49:\tlearn: 0.1152700\ttotal: 58.6s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: wash\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 99/99 [00:06<00:00, 15.37it/s]\n",
      "Feature Extraction: 100%|██████████| 95/95 [00:01<00:00, 64.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: dryer\n",
      "\n",
      "0:\tlearn: 0.5750133\ttotal: 1.06s\tremaining: 52.1s\n",
      "1:\tlearn: 0.5075876\ttotal: 2.08s\tremaining: 49.9s\n",
      "2:\tlearn: 0.4372198\ttotal: 3.63s\tremaining: 56.8s\n",
      "3:\tlearn: 0.3767262\ttotal: 5.46s\tremaining: 1m 2s\n",
      "4:\tlearn: 0.3334218\ttotal: 7.03s\tremaining: 1m 3s\n",
      "5:\tlearn: 0.2909662\ttotal: 8.35s\tremaining: 1m 1s\n",
      "6:\tlearn: 0.2539043\ttotal: 9.59s\tremaining: 58.9s\n",
      "7:\tlearn: 0.2321505\ttotal: 10.8s\tremaining: 57s\n",
      "8:\tlearn: 0.2056101\ttotal: 12.3s\tremaining: 55.8s\n",
      "9:\tlearn: 0.1858559\ttotal: 13.8s\tremaining: 55.3s\n",
      "10:\tlearn: 0.1704684\ttotal: 15.1s\tremaining: 53.6s\n",
      "11:\tlearn: 0.1570879\ttotal: 16.6s\tremaining: 52.4s\n",
      "12:\tlearn: 0.1413557\ttotal: 17.8s\tremaining: 50.6s\n",
      "13:\tlearn: 0.1271780\ttotal: 19.1s\tremaining: 49.2s\n",
      "14:\tlearn: 0.1208051\ttotal: 20.6s\tremaining: 48.1s\n",
      "15:\tlearn: 0.1128903\ttotal: 22s\tremaining: 46.7s\n",
      "16:\tlearn: 0.1058970\ttotal: 23.2s\tremaining: 45s\n",
      "17:\tlearn: 0.0998455\ttotal: 24.3s\tremaining: 43.2s\n",
      "18:\tlearn: 0.0957092\ttotal: 25.4s\tremaining: 41.4s\n",
      "19:\tlearn: 0.0901780\ttotal: 26.4s\tremaining: 39.6s\n",
      "20:\tlearn: 0.0854641\ttotal: 27.6s\tremaining: 38.2s\n",
      "21:\tlearn: 0.0819769\ttotal: 28.7s\tremaining: 36.5s\n",
      "22:\tlearn: 0.0764762\ttotal: 29.8s\tremaining: 35s\n",
      "23:\tlearn: 0.0739398\ttotal: 31s\tremaining: 33.6s\n",
      "24:\tlearn: 0.0708926\ttotal: 32.1s\tremaining: 32.1s\n",
      "25:\tlearn: 0.0684011\ttotal: 33.1s\tremaining: 30.6s\n",
      "26:\tlearn: 0.0656309\ttotal: 34.2s\tremaining: 29.1s\n",
      "27:\tlearn: 0.0633243\ttotal: 35.3s\tremaining: 27.8s\n",
      "28:\tlearn: 0.0595157\ttotal: 36.5s\tremaining: 26.5s\n",
      "29:\tlearn: 0.0572559\ttotal: 37.6s\tremaining: 25.1s\n",
      "30:\tlearn: 0.0542453\ttotal: 38.8s\tremaining: 23.8s\n",
      "31:\tlearn: 0.0514924\ttotal: 39.9s\tremaining: 22.5s\n",
      "32:\tlearn: 0.0491432\ttotal: 41.1s\tremaining: 21.2s\n",
      "33:\tlearn: 0.0470211\ttotal: 42.3s\tremaining: 19.9s\n",
      "34:\tlearn: 0.0450701\ttotal: 43.6s\tremaining: 18.7s\n",
      "35:\tlearn: 0.0436282\ttotal: 44.8s\tremaining: 17.4s\n",
      "36:\tlearn: 0.0425914\ttotal: 46s\tremaining: 16.2s\n",
      "37:\tlearn: 0.0413298\ttotal: 47.2s\tremaining: 14.9s\n",
      "38:\tlearn: 0.0403493\ttotal: 48.3s\tremaining: 13.6s\n",
      "39:\tlearn: 0.0386587\ttotal: 49.3s\tremaining: 12.3s\n",
      "40:\tlearn: 0.0372654\ttotal: 50.5s\tremaining: 11.1s\n",
      "41:\tlearn: 0.0365055\ttotal: 52.2s\tremaining: 9.94s\n",
      "42:\tlearn: 0.0353565\ttotal: 54.1s\tremaining: 8.81s\n",
      "43:\tlearn: 0.0344749\ttotal: 55.7s\tremaining: 7.59s\n",
      "44:\tlearn: 0.0336004\ttotal: 56.8s\tremaining: 6.31s\n",
      "45:\tlearn: 0.0325740\ttotal: 57.8s\tremaining: 5.03s\n",
      "46:\tlearn: 0.0317958\ttotal: 59s\tremaining: 3.76s\n",
      "47:\tlearn: 0.0311293\ttotal: 60s\tremaining: 2.5s\n",
      "48:\tlearn: 0.0302001\ttotal: 1m 1s\tremaining: 1.25s\n",
      "49:\tlearn: 0.0297076\ttotal: 1m 3s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: dryer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ac</th>\n",
       "      <th>ev</th>\n",
       "      <th>oven</th>\n",
       "      <th>wash</th>\n",
       "      <th>dryer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ac  ev  oven  wash  dryer\n",
       "0   1   0   1     0     0      1\n",
       "1   2   0   1     0     0      1\n",
       "2   3   0   1     0     0      1\n",
       "3   4   0   1     0     1      1\n",
       "4   5   0   1     0     0      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "%matplotlib inline\n",
    "import re\n",
    "from io import StringIO\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, make_scorer, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from tsfresh import extract_features\n",
    "import itertools\n",
    "import torch # for getting information if GPU is present\n",
    "\n",
    "\n",
    "\n",
    "# Reading the csv files for initial cleaning of the data\n",
    "train_df = pd.read_csv(\"train_data_withlabels.csv\")\n",
    "test_df = pd.read_csv(\"test_data_nolabels.csv\")\n",
    "\n",
    "\n",
    "# Function for splitting the train data and putting it in dictionary\n",
    "def creating_data_dicts(train_data, train_data_dict,\n",
    "                        test_data, test_data_dict):\n",
    "    \n",
    "    '''\n",
    "    This function would split the train dataframe into 1000 rows\n",
    "    and complete rows and the insert it in the dictionary with\n",
    "    appropriate key.\n",
    "    Params:\n",
    "    1. train_data: This the train data which would be splitted.\n",
    "    2. train_data_dict: This is the dictionary in which the data is inserted.\n",
    "    3. for_data: This indicates the type of data for which we would be creating\n",
    "                 the split.\n",
    "    \n",
    "    Returns\n",
    "    1. train_data_dict: The train data dict would be returned with the split\n",
    "                        inserted in it.\n",
    "    '''\n",
    "\n",
    "    # Static part of the keys for the dictionaries\n",
    "    class_list = ['ac', 'ev', 'oven', 'wash', 'dryer']\n",
    "\n",
    "    # Creating the keys for the resultant dictionary\n",
    "    # with concatenating the static and dynamic part\n",
    "    key_list_train = [item + '_' + 'trainData' for item in class_list]\n",
    "\n",
    "    # Looping to create different dataframes with different classes\n",
    "    for i in range(len(key_list_train)):\n",
    "        \n",
    "        train_data_label = train_data.rename(columns =\\\n",
    "                                                     {class_list[i]: 'label'})\n",
    "        \n",
    "        train_data_dict[key_list_train[i]] = train_data_label[['Unnamed: 0','load','hourofday','dayofweek',\\\n",
    "                                                         'dif','absdif','max','var','entropy',\\\n",
    "                                                         'nonlinear','hurst','label']]\n",
    "        \n",
    "    key_list_test = [item + '_' + 'testData' for item in class_list]\n",
    "    \n",
    "    \n",
    "    # Looping to create different dataframes with different classes\n",
    "    for i in range(len(key_list_test)):\n",
    "        \n",
    "        test_data_dict[key_list_test[i]] = test_data\n",
    "    \n",
    "\n",
    "    return train_data_dict, test_data_dict\n",
    "\n",
    "\n",
    "\n",
    "train_data_dict = dict()\n",
    "test_data_dict = dict()\n",
    "train_data_dict, test_data_dict = creating_data_dicts(train_df, train_data_dict,\n",
    "                                                      test_df, test_data_dict)\n",
    "\n",
    "\n",
    "# # Fucntion to perform cleaning in the dataframe\n",
    "def cleaning_df(df,df_type = 'Train Dataframe'):\n",
    "    \n",
    "    '''\n",
    "    This function is used to perform the basic dataframe cleaning like\n",
    "        * Removing the columns which are not required for prediction\n",
    "        * Removing the duplicates\n",
    "        * Removing the rows with NA values:\n",
    "            * For train dataframe all the required columns will be checked.\n",
    "            * For test dataframe only Abstract column will be checked.\n",
    "        \n",
    "        Counts before and after the cleaning will be displayed.\n",
    "    Params:\n",
    "    1. df: The datfarame that needs to be cleaned.\n",
    "    2. df_type: The type of df that requires cleaning i.e. Training or Testing\n",
    "    '''    \n",
    "    \n",
    "    print(f'Number of rows before removing duplicates from {df_type}:', \\\n",
    "          len(df))\n",
    "    \n",
    "    if df_type != 'Test Dataframe':\n",
    "        # Removing duplicates in case of train dataframe\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f'Number of rows after removing duplicates from {df_type}:', \\\n",
    "              len(df))\n",
    "        print(f'Number of rows before removing missing values from {df_type}:',\\\n",
    "          len(df))\n",
    "        # Removing the NAs in the train dataframe\n",
    "        df = df.dropna()\n",
    "    else:\n",
    "        print(f'Number of rows before removing missing values from {df_type}:',\\\n",
    "          len(df))\n",
    "        # Removing the NAs in the test dataframe\n",
    "        df = df.dropna()\n",
    "\n",
    "    print(f'Number of rows after removing missing values from {df_type}:',\\\n",
    "          len(df))\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "    return df\n",
    "\n",
    "for key, item in train_data_dict.items():\n",
    "    key_split = key.split('_')\n",
    "    print(f'The below statements are for the dataframe for {key_split[0]}')\n",
    "    train_data_dict[key] = cleaning_df(item, df_type = 'Train Dataframe')\n",
    "    \n",
    "for key, item in test_data_dict.items():\n",
    "    key_split = key.split('_')\n",
    "    print(f'The below statements are for the dataframe for {key_split[0]}')\n",
    "    test_data_dict[key] = cleaning_df(item, df_type = 'Test Dataframe')\n",
    "    \n",
    "    \n",
    "\n",
    "def one_hot_encoding(df, column_list, prefixes_list):\n",
    "    \n",
    "    y = []\n",
    "    y.append(df)\n",
    "    for i in range(len(column_list)):\n",
    "        y.append(pd.get_dummies(df[column_list[i]], prefix=prefixes_list[i]))\n",
    "        y[i+1] = y[i+1].drop(columns=y[i+1].columns[0], axis = 1)\n",
    "    \n",
    "    y[0] = y[0].drop(column_list, axis = 1)\n",
    "    \n",
    "    df = pd.concat(y, axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def average_window_appliance_was_on(train_df):\n",
    "    \n",
    "    n = train_df.groupby((train_df['label']!=\\\n",
    "                              train_df['label'].shift(1)).\\\n",
    "                             cumsum()).count().shape[0]\n",
    "    \n",
    "    if not n%2 == 0:\n",
    "        return round(train_df['label'].value_counts()[1]/((n-1)/2))\n",
    "    else:\n",
    "        return round(train_df['label'].value_counts()[1]/(n/2))\n",
    "\n",
    "    \n",
    "def create_ts_features(df, window):\n",
    "\n",
    "    df = df.rename(columns = {'Unnamed: 0': 'time'})\n",
    "    \n",
    "    df['id'] = ((df.index/window) + 1).astype(int)\n",
    "\n",
    "    timeseries = df[['id','time', 'load']]\n",
    "\n",
    "    settings =  {'variance_larger_than_standard_deviation': None,\n",
    "                'abs_energy': None,\n",
    "                'mean_abs_change': None,\n",
    "                'mean_change': None,\n",
    "                'mean_second_derivative_central': None,\n",
    "                'median': None,\n",
    "                'standard_deviation': None,\n",
    "                'variation_coefficient': None,\n",
    "                'variance': None,\n",
    "                'root_mean_square': None,\n",
    "                'benford_correlation': None,\n",
    "                'time_reversal_asymmetry_statistic': [{'lag': 1}, {'lag': 2}, {'lag': 3}],\n",
    "                'c3': [{'lag': 1}, {'lag': 2}, {'lag': 3}],\n",
    "                'large_standard_deviation': [{'r': 0.05},\n",
    "                 {'r': 0.1}],\n",
    "                'linear_trend': [{'attr': 'pvalue'},\n",
    "                 {'attr': 'rvalue'},\n",
    "                 {'attr': 'intercept'},\n",
    "                 {'attr': 'slope'},\n",
    "                 {'attr': 'stderr'}],\n",
    "                'linear_trend_timewise': [{'attr': 'pvalue'},\n",
    "                 {'attr': 'rvalue'},\n",
    "                 {'attr': 'intercept'},\n",
    "                 {'attr': 'slope'},\n",
    "                 {'attr': 'stderr'}]}\n",
    "    \n",
    "    extracted_features = extract_features(timeseries, column_id=\"id\",\\\n",
    "                                          column_sort=\"time\", n_jobs = 20,\\\n",
    "                                          default_fc_parameters=settings)\n",
    "    \n",
    "    extracted_features['id'] = extracted_features.index\n",
    "    \n",
    "    df = pd.merge(df, extracted_features, how=\"left\",on='id')\n",
    "    \n",
    "    df = df.dropna(axis=1)\n",
    "    \n",
    "    df = df.drop(['time','id'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def logisticRegression_model(x_train, y_train, x_test, label):\n",
    "    \n",
    "    model = LogisticRegression(random_state=111, n_jobs = -1, C = 1,\\\n",
    "                               max_iter = 2000, solver='newton-cg')\\\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    print('Building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    print('Finished building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "#     y_predict = model.predict(x_test)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def catboost_model(x_train, y_train, x_test, label):\n",
    "    \n",
    "    ylist = np.array(y_train)\n",
    "    model = CatBoostClassifier(random_state=111, task_type = 'GPU',\\\n",
    "                               class_weights=[1.0,(len(ylist[ylist == 0])/len(ylist[ylist == 1]))/2],\n",
    "                               iterations=50, learning_rate=0.1, max_depth = 13)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    print('Building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    print('Finished building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    \n",
    "#     y_predict = model.predict(x_test)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    cb_model_type = 'GPU'\n",
    "else:\n",
    "    cb_model_type = 'CPU'\n",
    "\n",
    "# Getting the list of the keys from the test_data_dict dictionary\n",
    "test_data_dict_key_list = [*test_data_dict]\n",
    "i = 0\n",
    "\n",
    "pred_labels_list = []\n",
    "predictions_list = []\n",
    "\n",
    "# Looping over the train_data_dict dictionary\n",
    "for key, tr_df in train_data_dict.items():\n",
    "    \n",
    "    # Picking the ith key from the test_data_dict dictionary\n",
    "    test_df_key = test_data_dict_key_list[i]\n",
    "    # Getting the dataframe associated with the test dictionary key\n",
    "    x_test = test_data_dict[test_df_key]\n",
    "\n",
    "    # Splitting the key from the train_data_dict\n",
    "    train_key_split = key.split('_')\n",
    "    \n",
    "    # Getting the label\n",
    "    label = train_key_split[0]\n",
    "\n",
    "    tr_df = one_hot_encoding(tr_df, ['dayofweek'], ['dayofweek'])\n",
    "\n",
    "    window = average_window_appliance_was_on(tr_df)\n",
    "    x_train = create_ts_features(tr_df, window)\n",
    "\n",
    "    \n",
    "    x_test = one_hot_encoding(x_test, ['dayofweek'], ['dayofweek'])\n",
    "    x_test = create_ts_features(x_test, window)\n",
    "\n",
    "    if label == 'ev':\n",
    "        model = LogisticRegression(C = 1, max_iter = 2000, solver = 'newton-cg',\\\n",
    "                                   random_state=111, n_jobs = -1)\n",
    "    else:\n",
    "        ylist = x_train['label'].values\n",
    "            # Predicting the target variable with the already tuned hyperparameters\n",
    "        model = CatBoostClassifier(random_state=111, task_type = cb_model_type,\\\n",
    "                                class_weights=[1.0,len(ylist[ylist == 0])/len(ylist[ylist == 1])],\n",
    "                                iterations = 50, learning_rate = 0.1, max_depth = 13)\n",
    "\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    print('Building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    \n",
    "    model.fit(x_train.loc[:, x_train.columns.difference(['label'])],\\\n",
    "              np.asarray(x_train['label'].tolist()))\n",
    "    \n",
    "    print('Finished building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "        \n",
    "    # Do the prediction\n",
    "    pred_labels_list.append(pd.DataFrame({label: model.predict(x_test)}))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "pred_labels_df = pd.concat(pred_labels_list, axis = 1)\n",
    "# pred_labels_df.insert(0, \"col.index\", list(range(1,(len(pred_labels_df) + 1))))\n",
    "pred_labels_df.insert(0, \"id\", list(range(1,(len(pred_labels_df) + 1))))\n",
    "pred_labels_df.to_csv('pred_labels.csv',index = False)\n",
    "pred_labels_df.head() #optional can be reomved later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [00:23<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size for Label : ac is =21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 99/99 [00:05<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: ac\n",
      "\n",
      "0:\tlearn: 0.4153349\ttotal: 1.19s\tremaining: 58.2s\n",
      "1:\tlearn: 0.2518350\ttotal: 2.33s\tremaining: 56s\n",
      "2:\tlearn: 0.1585842\ttotal: 3.6s\tremaining: 56.3s\n",
      "3:\tlearn: 0.1073081\ttotal: 4.75s\tremaining: 54.6s\n",
      "4:\tlearn: 0.0795874\ttotal: 5.81s\tremaining: 52.3s\n",
      "5:\tlearn: 0.0627084\ttotal: 7.09s\tremaining: 52s\n",
      "6:\tlearn: 0.0491076\ttotal: 8.21s\tremaining: 50.4s\n",
      "7:\tlearn: 0.0400897\ttotal: 9.37s\tremaining: 49.2s\n",
      "8:\tlearn: 0.0341203\ttotal: 10.5s\tremaining: 47.7s\n",
      "9:\tlearn: 0.0300008\ttotal: 11.6s\tremaining: 46.4s\n",
      "10:\tlearn: 0.0270095\ttotal: 12.8s\tremaining: 45.3s\n",
      "11:\tlearn: 0.0246721\ttotal: 13.8s\tremaining: 43.8s\n",
      "12:\tlearn: 0.0230699\ttotal: 14.9s\tremaining: 42.4s\n",
      "13:\tlearn: 0.0213968\ttotal: 16s\tremaining: 41.1s\n",
      "14:\tlearn: 0.0199259\ttotal: 17s\tremaining: 39.7s\n",
      "15:\tlearn: 0.0192003\ttotal: 18.1s\tremaining: 38.5s\n",
      "16:\tlearn: 0.0182339\ttotal: 19.2s\tremaining: 37.3s\n",
      "17:\tlearn: 0.0175672\ttotal: 20.3s\tremaining: 36s\n",
      "18:\tlearn: 0.0167914\ttotal: 21.3s\tremaining: 34.8s\n",
      "19:\tlearn: 0.0162423\ttotal: 22.4s\tremaining: 33.6s\n",
      "20:\tlearn: 0.0157449\ttotal: 23.4s\tremaining: 32.3s\n",
      "21:\tlearn: 0.0152069\ttotal: 24.4s\tremaining: 31.1s\n",
      "22:\tlearn: 0.0148417\ttotal: 25.5s\tremaining: 29.9s\n",
      "23:\tlearn: 0.0142888\ttotal: 26.6s\tremaining: 28.8s\n",
      "24:\tlearn: 0.0140642\ttotal: 27.6s\tremaining: 27.6s\n",
      "25:\tlearn: 0.0134667\ttotal: 28.7s\tremaining: 26.5s\n",
      "26:\tlearn: 0.0131191\ttotal: 29.8s\tremaining: 25.4s\n",
      "27:\tlearn: 0.0126982\ttotal: 30.8s\tremaining: 24.2s\n",
      "28:\tlearn: 0.0123148\ttotal: 32s\tremaining: 23.2s\n",
      "29:\tlearn: 0.0120050\ttotal: 33.2s\tremaining: 22.1s\n",
      "30:\tlearn: 0.0117685\ttotal: 34.3s\tremaining: 21s\n",
      "31:\tlearn: 0.0115388\ttotal: 35.5s\tremaining: 20s\n",
      "32:\tlearn: 0.0111601\ttotal: 36.6s\tremaining: 18.9s\n",
      "33:\tlearn: 0.0109282\ttotal: 37.9s\tremaining: 17.8s\n",
      "34:\tlearn: 0.0106305\ttotal: 39s\tremaining: 16.7s\n",
      "35:\tlearn: 0.0104587\ttotal: 40.1s\tremaining: 15.6s\n",
      "36:\tlearn: 0.0101739\ttotal: 41.3s\tremaining: 14.5s\n",
      "37:\tlearn: 0.0099953\ttotal: 43.2s\tremaining: 13.6s\n",
      "38:\tlearn: 0.0097265\ttotal: 44.9s\tremaining: 12.7s\n",
      "39:\tlearn: 0.0095501\ttotal: 46.8s\tremaining: 11.7s\n",
      "40:\tlearn: 0.0093889\ttotal: 48.2s\tremaining: 10.6s\n",
      "41:\tlearn: 0.0091536\ttotal: 49.7s\tremaining: 9.46s\n",
      "42:\tlearn: 0.0090532\ttotal: 51.1s\tremaining: 8.31s\n",
      "43:\tlearn: 0.0088988\ttotal: 52.3s\tremaining: 7.13s\n",
      "44:\tlearn: 0.0087579\ttotal: 53.4s\tremaining: 5.93s\n",
      "45:\tlearn: 0.0085127\ttotal: 54.5s\tremaining: 4.74s\n",
      "46:\tlearn: 0.0083627\ttotal: 55.7s\tremaining: 3.55s\n",
      "47:\tlearn: 0.0082088\ttotal: 56.8s\tremaining: 2.37s\n",
      "48:\tlearn: 0.0080538\ttotal: 58.1s\tremaining: 1.19s\n",
      "49:\tlearn: 0.0079550\ttotal: 59.3s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: ac\n",
      "\n",
      "Start prediction using CatBoostClassifier model for label: ac\n",
      "\n",
      "Finished prediction using CatBoostClassifier model for label: ac\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [00:06<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size for Label : ev is =69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 96/96 [00:01<00:00, 58.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LogisticRegression model for label: ev\n",
      "\n",
      "Finished building LogisticRegression model for label: ev\n",
      "\n",
      "Start prediction using LogisticRegression model for label: ev\n",
      "\n",
      "Finished prediction using LogisticRegression model for label: ev\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size for Label : oven is =6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [00:15<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: oven\n",
      "\n",
      "0:\tlearn: 0.4883140\ttotal: 929ms\tremaining: 45.5s\n",
      "1:\tlearn: 0.3545935\ttotal: 1.84s\tremaining: 44.3s\n",
      "2:\tlearn: 0.2692829\ttotal: 2.79s\tremaining: 43.8s\n",
      "3:\tlearn: 0.2126644\ttotal: 3.82s\tremaining: 44s\n",
      "4:\tlearn: 0.1768594\ttotal: 4.76s\tremaining: 42.9s\n",
      "5:\tlearn: 0.1486666\ttotal: 5.82s\tremaining: 42.7s\n",
      "6:\tlearn: 0.1282920\ttotal: 6.88s\tremaining: 42.3s\n",
      "7:\tlearn: 0.1117640\ttotal: 7.82s\tremaining: 41s\n",
      "8:\tlearn: 0.0984935\ttotal: 8.75s\tremaining: 39.9s\n",
      "9:\tlearn: 0.0894134\ttotal: 9.71s\tremaining: 38.8s\n",
      "10:\tlearn: 0.0811792\ttotal: 10.7s\tremaining: 37.8s\n",
      "11:\tlearn: 0.0745617\ttotal: 11.7s\tremaining: 36.9s\n",
      "12:\tlearn: 0.0703409\ttotal: 12.6s\tremaining: 36s\n",
      "13:\tlearn: 0.0642889\ttotal: 13.6s\tremaining: 34.9s\n",
      "14:\tlearn: 0.0605929\ttotal: 14.6s\tremaining: 34s\n",
      "15:\tlearn: 0.0570588\ttotal: 15.5s\tremaining: 32.9s\n",
      "16:\tlearn: 0.0536220\ttotal: 16.4s\tremaining: 31.8s\n",
      "17:\tlearn: 0.0514037\ttotal: 17.4s\tremaining: 30.9s\n",
      "18:\tlearn: 0.0485824\ttotal: 18.3s\tremaining: 29.9s\n",
      "19:\tlearn: 0.0465300\ttotal: 19.3s\tremaining: 28.9s\n",
      "20:\tlearn: 0.0448600\ttotal: 20.2s\tremaining: 27.9s\n",
      "21:\tlearn: 0.0430352\ttotal: 21.1s\tremaining: 26.9s\n",
      "22:\tlearn: 0.0408695\ttotal: 22.1s\tremaining: 25.9s\n",
      "23:\tlearn: 0.0387750\ttotal: 23s\tremaining: 25s\n",
      "24:\tlearn: 0.0371327\ttotal: 24s\tremaining: 24s\n",
      "25:\tlearn: 0.0357698\ttotal: 25s\tremaining: 23.1s\n",
      "26:\tlearn: 0.0344981\ttotal: 25.9s\tremaining: 22.1s\n",
      "27:\tlearn: 0.0332557\ttotal: 26.9s\tremaining: 21.1s\n",
      "28:\tlearn: 0.0320056\ttotal: 27.8s\tremaining: 20.2s\n",
      "29:\tlearn: 0.0309670\ttotal: 28.8s\tremaining: 19.2s\n",
      "30:\tlearn: 0.0297633\ttotal: 29.8s\tremaining: 18.3s\n",
      "31:\tlearn: 0.0288103\ttotal: 30.7s\tremaining: 17.3s\n",
      "32:\tlearn: 0.0281506\ttotal: 31.7s\tremaining: 16.3s\n",
      "33:\tlearn: 0.0275511\ttotal: 32.7s\tremaining: 15.4s\n",
      "34:\tlearn: 0.0267532\ttotal: 33.6s\tremaining: 14.4s\n",
      "35:\tlearn: 0.0261815\ttotal: 34.6s\tremaining: 13.4s\n",
      "36:\tlearn: 0.0255386\ttotal: 35.7s\tremaining: 12.5s\n",
      "37:\tlearn: 0.0250941\ttotal: 36.7s\tremaining: 11.6s\n",
      "38:\tlearn: 0.0244106\ttotal: 37.6s\tremaining: 10.6s\n",
      "39:\tlearn: 0.0237906\ttotal: 38.6s\tremaining: 9.64s\n",
      "40:\tlearn: 0.0232709\ttotal: 39.5s\tremaining: 8.67s\n",
      "41:\tlearn: 0.0224750\ttotal: 40.4s\tremaining: 7.7s\n",
      "42:\tlearn: 0.0218602\ttotal: 41.4s\tremaining: 6.73s\n",
      "43:\tlearn: 0.0213692\ttotal: 42.3s\tremaining: 5.77s\n",
      "44:\tlearn: 0.0210548\ttotal: 43.3s\tremaining: 4.81s\n",
      "45:\tlearn: 0.0206949\ttotal: 44.2s\tremaining: 3.84s\n",
      "46:\tlearn: 0.0199944\ttotal: 45.2s\tremaining: 2.88s\n",
      "47:\tlearn: 0.0194797\ttotal: 46.2s\tremaining: 1.92s\n",
      "48:\tlearn: 0.0188938\ttotal: 47.2s\tremaining: 963ms\n",
      "49:\tlearn: 0.0183001\ttotal: 48.2s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: oven\n",
      "\n",
      "Start prediction using CatBoostClassifier model for label: oven\n",
      "\n",
      "Finished prediction using CatBoostClassifier model for label: oven\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [01:01<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size for Label : wash is =6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 100/100 [00:17<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: wash\n",
      "\n",
      "0:\tlearn: 0.6001776\ttotal: 1.19s\tremaining: 58.1s\n",
      "1:\tlearn: 0.5287165\ttotal: 2.27s\tremaining: 54.4s\n",
      "2:\tlearn: 0.4807273\ttotal: 3.57s\tremaining: 56s\n",
      "3:\tlearn: 0.4472775\ttotal: 5.31s\tremaining: 1m 1s\n",
      "4:\tlearn: 0.4150371\ttotal: 7.05s\tremaining: 1m 3s\n",
      "5:\tlearn: 0.3865736\ttotal: 8.77s\tremaining: 1m 4s\n",
      "6:\tlearn: 0.3734562\ttotal: 10.4s\tremaining: 1m 3s\n",
      "7:\tlearn: 0.3609680\ttotal: 11.9s\tremaining: 1m 2s\n",
      "8:\tlearn: 0.3418632\ttotal: 13.2s\tremaining: 1m\n",
      "9:\tlearn: 0.3282036\ttotal: 15s\tremaining: 59.9s\n",
      "10:\tlearn: 0.3203937\ttotal: 16.6s\tremaining: 58.9s\n",
      "11:\tlearn: 0.3058220\ttotal: 18.2s\tremaining: 57.6s\n",
      "12:\tlearn: 0.2973277\ttotal: 19.6s\tremaining: 55.7s\n",
      "13:\tlearn: 0.2873282\ttotal: 20.8s\tremaining: 53.6s\n",
      "14:\tlearn: 0.2730401\ttotal: 22s\tremaining: 51.4s\n",
      "15:\tlearn: 0.2643064\ttotal: 23.2s\tremaining: 49.3s\n",
      "16:\tlearn: 0.2517835\ttotal: 24.4s\tremaining: 47.3s\n",
      "17:\tlearn: 0.2445017\ttotal: 25.5s\tremaining: 45.3s\n",
      "18:\tlearn: 0.2376645\ttotal: 26.6s\tremaining: 43.4s\n",
      "19:\tlearn: 0.2318810\ttotal: 27.7s\tremaining: 41.5s\n",
      "20:\tlearn: 0.2246472\ttotal: 28.8s\tremaining: 39.8s\n",
      "21:\tlearn: 0.2181498\ttotal: 29.9s\tremaining: 38.1s\n",
      "22:\tlearn: 0.2127148\ttotal: 31.1s\tremaining: 36.5s\n",
      "23:\tlearn: 0.2069462\ttotal: 32.2s\tremaining: 34.9s\n",
      "24:\tlearn: 0.2005885\ttotal: 33.3s\tremaining: 33.3s\n",
      "25:\tlearn: 0.1946294\ttotal: 34.4s\tremaining: 31.8s\n",
      "26:\tlearn: 0.1886817\ttotal: 35.6s\tremaining: 30.3s\n",
      "27:\tlearn: 0.1857403\ttotal: 36.7s\tremaining: 28.8s\n",
      "28:\tlearn: 0.1818018\ttotal: 37.8s\tremaining: 27.4s\n",
      "29:\tlearn: 0.1782969\ttotal: 38.9s\tremaining: 25.9s\n",
      "30:\tlearn: 0.1748445\ttotal: 40s\tremaining: 24.5s\n",
      "31:\tlearn: 0.1733307\ttotal: 41s\tremaining: 23.1s\n",
      "32:\tlearn: 0.1691406\ttotal: 42.1s\tremaining: 21.7s\n",
      "33:\tlearn: 0.1644331\ttotal: 43.1s\tremaining: 20.3s\n",
      "34:\tlearn: 0.1607502\ttotal: 44.3s\tremaining: 19s\n",
      "35:\tlearn: 0.1578760\ttotal: 45.3s\tremaining: 17.6s\n",
      "36:\tlearn: 0.1530237\ttotal: 46.4s\tremaining: 16.3s\n",
      "37:\tlearn: 0.1493128\ttotal: 47.6s\tremaining: 15s\n",
      "38:\tlearn: 0.1449774\ttotal: 48.7s\tremaining: 13.7s\n",
      "39:\tlearn: 0.1412810\ttotal: 49.8s\tremaining: 12.4s\n",
      "40:\tlearn: 0.1392025\ttotal: 50.8s\tremaining: 11.2s\n",
      "41:\tlearn: 0.1365426\ttotal: 51.9s\tremaining: 9.89s\n",
      "42:\tlearn: 0.1330710\ttotal: 53s\tremaining: 8.63s\n",
      "43:\tlearn: 0.1300628\ttotal: 54.1s\tremaining: 7.37s\n",
      "44:\tlearn: 0.1265636\ttotal: 55.2s\tremaining: 6.13s\n",
      "45:\tlearn: 0.1243273\ttotal: 56.3s\tremaining: 4.89s\n",
      "46:\tlearn: 0.1209047\ttotal: 57.3s\tremaining: 3.66s\n",
      "47:\tlearn: 0.1191225\ttotal: 58.5s\tremaining: 2.44s\n",
      "48:\tlearn: 0.1174577\ttotal: 59.8s\tremaining: 1.22s\n",
      "49:\tlearn: 0.1152700\ttotal: 1m\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: wash\n",
      "\n",
      "Start prediction using CatBoostClassifier model for label: wash\n",
      "\n",
      "Finished prediction using CatBoostClassifier model for label: wash\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 99/99 [00:04<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size for Label : dryer is =80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 95/95 [00:01<00:00, 64.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CatBoostClassifier model for label: dryer\n",
      "\n",
      "0:\tlearn: 0.5750133\ttotal: 1.37s\tremaining: 1m 7s\n",
      "1:\tlearn: 0.5075876\ttotal: 2.33s\tremaining: 56s\n",
      "2:\tlearn: 0.4372198\ttotal: 3.25s\tremaining: 51s\n",
      "3:\tlearn: 0.3767262\ttotal: 4.55s\tremaining: 52.3s\n",
      "4:\tlearn: 0.3334218\ttotal: 5.57s\tremaining: 50.1s\n",
      "5:\tlearn: 0.2909662\ttotal: 6.63s\tremaining: 48.6s\n",
      "6:\tlearn: 0.2539043\ttotal: 7.71s\tremaining: 47.4s\n",
      "7:\tlearn: 0.2321505\ttotal: 8.8s\tremaining: 46.2s\n",
      "8:\tlearn: 0.2056101\ttotal: 9.81s\tremaining: 44.7s\n",
      "9:\tlearn: 0.1858559\ttotal: 10.8s\tremaining: 43.4s\n",
      "10:\tlearn: 0.1704684\ttotal: 12s\tremaining: 42.7s\n",
      "11:\tlearn: 0.1570879\ttotal: 13.4s\tremaining: 42.3s\n",
      "12:\tlearn: 0.1413557\ttotal: 14.5s\tremaining: 41.2s\n",
      "13:\tlearn: 0.1271780\ttotal: 15.6s\tremaining: 40s\n",
      "14:\tlearn: 0.1208051\ttotal: 16.6s\tremaining: 38.8s\n",
      "15:\tlearn: 0.1128903\ttotal: 17.6s\tremaining: 37.5s\n",
      "16:\tlearn: 0.1058970\ttotal: 18.5s\tremaining: 36s\n",
      "17:\tlearn: 0.0998455\ttotal: 19.4s\tremaining: 34.5s\n",
      "18:\tlearn: 0.0957092\ttotal: 20.3s\tremaining: 33.1s\n",
      "19:\tlearn: 0.0901780\ttotal: 21.1s\tremaining: 31.7s\n",
      "20:\tlearn: 0.0854641\ttotal: 22.2s\tremaining: 30.7s\n",
      "21:\tlearn: 0.0819769\ttotal: 23.2s\tremaining: 29.6s\n",
      "22:\tlearn: 0.0764762\ttotal: 24.2s\tremaining: 28.4s\n",
      "23:\tlearn: 0.0739398\ttotal: 25.4s\tremaining: 27.5s\n",
      "24:\tlearn: 0.0708926\ttotal: 26.5s\tremaining: 26.5s\n",
      "25:\tlearn: 0.0684011\ttotal: 27.7s\tremaining: 25.5s\n",
      "26:\tlearn: 0.0656309\ttotal: 28.8s\tremaining: 24.5s\n",
      "27:\tlearn: 0.0633243\ttotal: 29.9s\tremaining: 23.5s\n",
      "28:\tlearn: 0.0595157\ttotal: 31.1s\tremaining: 22.5s\n",
      "29:\tlearn: 0.0572559\ttotal: 32.3s\tremaining: 21.5s\n",
      "30:\tlearn: 0.0542453\ttotal: 33.5s\tremaining: 20.5s\n",
      "31:\tlearn: 0.0514924\ttotal: 34.5s\tremaining: 19.4s\n",
      "32:\tlearn: 0.0491432\ttotal: 35.8s\tremaining: 18.4s\n",
      "33:\tlearn: 0.0470211\ttotal: 37.1s\tremaining: 17.4s\n",
      "34:\tlearn: 0.0450701\ttotal: 38.2s\tremaining: 16.4s\n",
      "35:\tlearn: 0.0436282\ttotal: 39.4s\tremaining: 15.3s\n",
      "36:\tlearn: 0.0425914\ttotal: 40.5s\tremaining: 14.2s\n",
      "37:\tlearn: 0.0413298\ttotal: 41.6s\tremaining: 13.1s\n",
      "38:\tlearn: 0.0403493\ttotal: 42.7s\tremaining: 12s\n",
      "39:\tlearn: 0.0386587\ttotal: 43.8s\tremaining: 10.9s\n",
      "40:\tlearn: 0.0372654\ttotal: 44.9s\tremaining: 9.86s\n",
      "41:\tlearn: 0.0365055\ttotal: 46.1s\tremaining: 8.79s\n",
      "42:\tlearn: 0.0353565\ttotal: 47.1s\tremaining: 7.67s\n",
      "43:\tlearn: 0.0344749\ttotal: 48.1s\tremaining: 6.56s\n",
      "44:\tlearn: 0.0336004\ttotal: 49.1s\tremaining: 5.45s\n",
      "45:\tlearn: 0.0325740\ttotal: 50.1s\tremaining: 4.35s\n",
      "46:\tlearn: 0.0317958\ttotal: 51s\tremaining: 3.26s\n",
      "47:\tlearn: 0.0311293\ttotal: 52s\tremaining: 2.17s\n",
      "48:\tlearn: 0.0302001\ttotal: 53s\tremaining: 1.08s\n",
      "49:\tlearn: 0.0297076\ttotal: 53.9s\tremaining: 0us\n",
      "Finished building CatBoostClassifier model for label: dryer\n",
      "\n",
      "Start prediction using CatBoostClassifier model for label: dryer\n",
      "\n",
      "Finished prediction using CatBoostClassifier model for label: dryer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ac</th>\n",
       "      <th>ev</th>\n",
       "      <th>oven</th>\n",
       "      <th>wash</th>\n",
       "      <th>dryer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ac  ev  oven  wash  dryer\n",
       "0   1   0   1     0     0      1\n",
       "1   2   0   1     0     0      1\n",
       "2   3   0   1     0     0      1\n",
       "3   4   0   1     0     1      1\n",
       "4   5   0   1     0     0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import warnings\n",
    "import sklearn\n",
    "from catboost import CatBoostClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from tsfresh import extract_features\n",
    "import torch # for getting information if GPU is present\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# Reading the training data csv files \n",
    "train_df = pd.read_csv(\"train_data_withlabels.csv\")\n",
    "# Reading the testing data csv files \n",
    "test_df = pd.read_csv(\"test_data_nolabels.csv\")\n",
    "\n",
    "\n",
    "# Function for splitting the train data and putting it in dictionary\n",
    "def creating_data_dicts(train_data, train_data_dict):\n",
    "    \n",
    "    '''\n",
    "    This function would split the train dataframe into 1000 rows\n",
    "    and complete rows and the insert it in the dictionary with\n",
    "    appropriate key.\n",
    "    Params:\n",
    "    1. train_data: This the train data which would be splitted.\n",
    "    2. train_data_dict: This is the dictionary in which the data is inserted.\n",
    "    3. for_data: This indicates the type of data for which we would be creating\n",
    "                 the split.\n",
    "    \n",
    "    Returns\n",
    "    1. train_data_dict: The train data dict would be returned with the split\n",
    "                        inserted in it.\n",
    "    '''\n",
    "\n",
    "    # Static part of the keys for the dictionaries\n",
    "    class_list = ['ac', 'ev', 'oven', 'wash', 'dryer']\n",
    "\n",
    "    # Creating the keys for the resultant dictionary\n",
    "    # with concatenating the static and dynamic part\n",
    "    key_list_train = [item + '_' + 'trainData' for item in class_list]\n",
    "\n",
    "    # Looping to create different dataframes with different classes\n",
    "    for i in range(len(key_list_train)):\n",
    "        # \n",
    "        train_data_label = train_data.rename(columns =\\\n",
    "                                                     {class_list[i]: 'label'})\n",
    "        \n",
    "        # \n",
    "        train_data_dict[key_list_train[i]] = train_data_label[['Unnamed: 0','load','hourofday','dayofweek',\\\n",
    "                                                         'dif','absdif','max','var','entropy',\\\n",
    "                                                         'nonlinear','hurst','label']]\n",
    "    \n",
    "    #    \n",
    "    key_list_test = [item + '_' + 'testData' for item in class_list]\n",
    "\n",
    "    return train_data_dict\n",
    "\n",
    "\n",
    "# Initialize a dictionary for the training data \n",
    "train_data_dict = dict()\n",
    "# test_data_dict = dict()\n",
    "# Creating entries for each label in the training dictionary \n",
    "train_data_dict = creating_data_dicts(train_df, train_data_dict)\n",
    "\n",
    "  \n",
    "\n",
    "def one_hot_encoding(df, column_list, prefixes_list):\n",
    "    \n",
    "    y = []\n",
    "    y.append(df)\n",
    "    for i in range(len(column_list)):\n",
    "        y.append(pd.get_dummies(df[column_list[i]], prefix=prefixes_list[i]))\n",
    "        y[i+1] = y[i+1].drop(columns=y[i+1].columns[0], axis = 1)\n",
    "    \n",
    "    y[0] = y[0].drop(column_list, axis = 1)\n",
    "    \n",
    "    df = pd.concat(y, axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def average_window_appliance_was_on(train_df):\n",
    "    \n",
    "    #\n",
    "    n = train_df.groupby((train_df['label']!=\\\n",
    "                              train_df['label'].shift(1)).\\\n",
    "                             cumsum()).count().shape[0]\n",
    "    \n",
    "    if not n%2 == 0:\n",
    "        return round(train_df['label'].value_counts()[1]/((n-1)/2))\n",
    "    else:\n",
    "        return round(train_df['label'].value_counts()[1]/(n/2))\n",
    "\n",
    "    \n",
    "def create_ts_features(df, window):\n",
    "\n",
    "    # Rename the 'Unnamed' column to 'time'\n",
    "    df = df.rename(columns = {'Unnamed: 0': 'time'})\n",
    "    \n",
    "    # Create a column 'id' that is the \n",
    "    df['id'] = ((df.index/window) + 1).astype(int)\n",
    "    \n",
    "    # Get the required subset of columns\n",
    "    timeseries = df[['id','time', 'load']]\n",
    "\n",
    "    settings =  {'variance_larger_than_standard_deviation': None,\n",
    "                'abs_energy': None,\n",
    "                'mean_abs_change': None,\n",
    "                'mean_change': None,\n",
    "                'mean_second_derivative_central': None,\n",
    "                'median': None,\n",
    "                'standard_deviation': None,\n",
    "                'variation_coefficient': None,\n",
    "                'variance': None,\n",
    "                'root_mean_square': None,\n",
    "                'benford_correlation': None,\n",
    "                'time_reversal_asymmetry_statistic': [{'lag': 1}, {'lag': 2}, {'lag': 3}],\n",
    "                'c3': [{'lag': 1}, {'lag': 2}, {'lag': 3}],\n",
    "                'large_standard_deviation': [{'r': 0.05},\n",
    "                 {'r': 0.1}],\n",
    "                'linear_trend': [{'attr': 'pvalue'},\n",
    "                 {'attr': 'rvalue'},\n",
    "                 {'attr': 'intercept'},\n",
    "                 {'attr': 'slope'},\n",
    "                 {'attr': 'stderr'}],\n",
    "                'linear_trend_timewise': [{'attr': 'pvalue'},\n",
    "                 {'attr': 'rvalue'},\n",
    "                 {'attr': 'intercept'},\n",
    "                 {'attr': 'slope'},\n",
    "                 {'attr': 'stderr'}]}\n",
    "    \n",
    "    #\n",
    "    extracted_features = extract_features(timeseries, column_id=\"id\",\\\n",
    "                                          column_sort=\"time\", n_jobs = 20,\\\n",
    "                                          default_fc_parameters=settings)\n",
    "    \n",
    "    #\n",
    "    extracted_features['id'] = extracted_features.index\n",
    "    \n",
    "    # \n",
    "    df = pd.merge(df, extracted_features, how=\"left\",on='id')\n",
    "    \n",
    "    # Dropping all nas\n",
    "    df = df.dropna(axis=1)\n",
    "    \n",
    "    # Dropping the time and id columns \n",
    "    df = df.drop(['time','id'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Check if gpu is available \n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    \n",
    "    cb_model_type = 'GPU'\n",
    "else:\n",
    "    cb_model_type = 'CPU'\n",
    "\n",
    "# Getting the list of the keys from the test_data_dict dictionary\n",
    "# test_data_dict_key_list = [*test_data_dict]\n",
    "\n",
    "# i = 0\n",
    "# Initialize list of predictions \n",
    "pred_labels_list = []\n",
    "# # Initialize list of predictions \n",
    "# predictions_list = []\n",
    "\n",
    "# Looping over the train_data_dict dictionary\n",
    "for key, tr_df in train_data_dict.items():\n",
    "\n",
    "    # Splitting the key from the train_data_dict\n",
    "    train_key_split = key.split('_')\n",
    "    # Get deep copy of the test dataframe \n",
    "    x_test = deepcopy(test_df)\n",
    "    # Getting the appliance label from the train key\n",
    "    label = train_key_split[0]\n",
    "    \n",
    "    # Perform one hot encoding for the categorical column in the training data\n",
    "    tr_df = one_hot_encoding(tr_df, ['dayofweek'], ['dayofweek'])\n",
    "    \n",
    "    # Get the average window size for each appliance \n",
    "    window = average_window_appliance_was_on(tr_df)\n",
    "    # Create additional ts features for given training data\n",
    "    x_train = create_ts_features(tr_df, window)\n",
    "\n",
    "    print('Window size for Label : '+ str(label) + ' is =' +str(window))\n",
    "    \n",
    "    \n",
    "    # Perform one hote encoding for the categorical column in the testing data\n",
    "    x_test = one_hot_encoding(x_test, ['dayofweek'], ['dayofweek'])\n",
    "    # Create additional ts features for the test data \n",
    "    x_test = create_ts_features(x_test, window)\n",
    "    \n",
    "    # For 'ev' appliance we create a LogisticRegression model, for all other labels we use CatBoost model \n",
    "    if label == 'ev':\n",
    "        # Create logistice regression model with the optimized hyperparameters \n",
    "        model = LogisticRegression(C = 1, max_iter = 2000, solver = 'newton-cg',\\\n",
    "                                   random_state=111, n_jobs = -1)\n",
    "    else:\n",
    "        # Get list of labels values. \n",
    "        ylist = x_train['label'].values\n",
    "        # Predicting the target variable with the already tuned hyperparameters\n",
    "        # We add class weigths for the labels to account for the huge class imbalance present in each label. \n",
    "        model = CatBoostClassifier(random_state=111, task_type = cb_model_type,\\\n",
    "                                class_weights=[1.0,len(ylist[ylist == 0])/len(ylist[ylist == 1])],\n",
    "                                iterations = 50, learning_rate = 0.1, max_depth = 13)\n",
    "    # Get model name \n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    print('Building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    \n",
    "    # Fit the model on the training data \n",
    "    model.fit(x_train.loc[:, x_train.columns.difference(['label'])],\\\n",
    "              np.asarray(x_train['label'].tolist()))\n",
    "    \n",
    "    print('Finished building ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    print('Start prediction using ' + model_name + ' model for label: ' + label + '\\n')\n",
    "    # Get the predictions for the given label and append it to the predictions list \n",
    "    pred_labels_list.append(pd.DataFrame({label: model.predict(x_test)}))\n",
    "    print('Finished prediction using ' + model_name + ' model for label: ' + label + '\\n')\n",
    "\n",
    "# Create a dataframe from the predictions list\n",
    "pred_labels_df = pd.concat(pred_labels_list, axis = 1)\n",
    "# \n",
    "pred_labels_df.insert(0, \"id\", list(range(1,(len(pred_labels_df) + 1))))\n",
    "# Write the predictions dataframe to a csv \n",
    "pred_labels_df.to_csv('pred_labels.csv',index = False)\n",
    "pred_labels_df.head() #optional can be reomved later"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "code_30749964_latest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
